# Welcome

A companion to [Advanced R](https://adv-r.hadley.nz/rcpp.html#acknowledgments) and supplement to [Advanced R Solutions](https://advanced-r-solutions.rbind.io/names-and-values.html#copy-on-modify)

Recordings for the accompanied presentation for each chapter can be seen [here](https://www.youtube.com/watch?v=pQ-xDAPEQaw&list=PL3x6DOfs2NGi9lH7q-phZlPrl6HKXYDbn).

<!--chapter:end:01-preface.Rmd-->

# Names and Values

```{r, include=FALSE}
library(tidyverse)
library(kableExtra)
library(lobstr)
```

## 2.3 Copy-on-modify {-}

:::question
copy-on-modify vs copy-in-place: is one more preferable in certain situations?
:::

modify in place only happens when objects with a single binding get a special performance optimization and to environments.

## 2.2.2 Exercises {-}

:::question
Question 3 digs into the syntactically valid names created when using `read.csv()`, but what is the difference between quotation and backticks? 

If we create an example csv
```{r}
example2223 <- tibble(
  `if` = c(1,2,3),
  `_1234` = c(4,5,6),
  `column 1` = c(7,8,9)
)

write.csv(example2223, "example2223.csv", row.names = FALSE)
```

Import using adjusted column names to be syntactically valid:
```{r}
read.csv(file = "example2223.csv",check.names = TRUE)
```

Import using non-adjusted column names
```{r}
read.csv(file = "example2223.csv", check.names = FALSE)
```

Import using the tidyverse where names are not adjusted
```{r}
df_non_syntactic_name  <- read_csv(file = "example2223.csv")
```

However I really don´t understand the difference between backticks and quotation marks. For example when I select a column in the case of non-syntactic in the tidyverse I can use quotation marks or backticks 

```{r}
df_non_syntactic_name %>% select("if")
```

```{r, eval=FALSE}
df_non_syntactic_name %>% select(`if`)
```

But in base R, I can do this with quotation marks, but not backticks:

```{r, eval=FALSE}
df__non_syntactic_name["if"]
```

```
Error in `[.default`(df__non_syntactic_name, `if`) : invalid subscript type 'special'
```

According to `?Quotes` backticks are used for "non-standard variable names" but why in base R they don´t work to select columns but in the tidyverse they work to select variables?
:::

The easiest way to think about this is that backticks refer to objects while quotation marks refer to strings. `dplyr::select()` accepts object references as well as string references, while base R subsetting is done with a string or integer position.

## 2.3.2 Function calls {-}

:::question
Can we go over and break down figure in 2.3.2
:::

When you create this function:

```{r, eval=FALSE}
crazyfunction <- function(eh) {eh}
```

`eh` doesn't exist in memory at this point.

```{r, eval=FALSE}
x <- c(1,2,3)
```

x exists in memory.

```{r, eval=FALSE}
z <- crazyfunction(x) 
```

`z` now points at `x`, and `eh` still doesn't exist (except metaphorically in Canada). `eh` was created and exists WHILE `crazyfunction()` was being run, but doesn't get saved to the global environment, so after the function is run you can't see its memory reference. 

The round brackets `(eh)` list the arguments, the curly brackets `{eh}` define the operation that it's doing - and you're assigning it to `crazyfunction`. 

**R functions automatically return the result of the last expression** so when you call that object (the argument `eh`) it returns the value of that argument. This is called **implicit returns**

## 2.3.3 Lists {-}

:::question

Checking the address for a list and its copy we see they share the same references:

```{r}
l1 <- list(1,2,3)
l2 <- l1
identical(lobstr::ref(l1),lobstr::ref(l2))
lobstr::obj_addr(l1[[1]])
lobstr::obj_addr(l2[[1]])
```

But why isn't this the case for their subsets? Using `obj_addr` they have different addresses, but when we look at their references they are the same

```{r}
lobstr::obj_addr(l1[1])
lobstr::ref(l1[1])
lobstr::obj_addr(l2[1])
```


```{r}
identical(lobstr::obj_addr(l1[1]), lobstr::obj_addr(l2[1]))
```
:::

This is because using singular brackets wraps the value 1 in a new list that is created on the fly which will have a unique address. We can use double brackets to confirm our mental model that the sublists are also identical:

```{r}
identical(lobstr::obj_addr(l1[[1]]), lobstr::obj_addr(l2[[1]]))
```


:::question
What's the difference between these 2 addresses `<0x55d53fa975b8>` and `0x55d53fa975b8`?
:::

Nothing - it has to do with the printing method:

```{r}
x <- c(1, 2, 3)
print(tracemem(x))
cat(tracemem(x))
lobstr::obj_addr(x)
```

:::question
When would you prefer a deep copy of a list to a shallow copy? Is this something to consider when writing functions or package development or is this more something that's optimized behind the scenes?
:::

Automagical!

## 2.3.5 Character vectors {-}


:::question
Is there a way to clear the "global string pool"?
:::

According to [this post](https://community.rstudio.com/t/memory-usage-and-rs-global-string-pool/4762/3) it doesn't look like you can directly, but clearing all references to a string that's in the global string pool clears that string from the pool, eventually

## 2.3.6.2 Exercise {-}

:::question
When we look at `tracemem` when we modify `x` from an integer to numeric, x is assigned to three objects. The first is the integer, and the third numeric - so what's the intermediate type?

```{r, eval=FALSE}
x <- c(1L, 2L, 3L)
obj_addr(x)
tracemem(x)
x[[3]] <- 4
```

```
[1] "0x7f84b7fe2c88"
[1] "<0x7f84b7fe2c88>"
tracemem[0x7f84b7fe2c88 -> 0x7f84b7fe5288]: 
tracemem[0x7f84b7fe5288 -> 0x7f84bc0817c8]: 
```

What is `0x7f84b7fe5288` when the intermediate `x <- c(1L, 2L, 4)` is impossible?
:::

When we assign the new value as an integer there is no intermediate step. This probably means `c(1,2, NA)` is the intermediate step; creating an intermediate vector that's the same length of the final product with NA values at all locations that are new or to be changed

```{r}
x <- c(1L, 2L, 3L)
obj_addr(x)
tracemem(x)
x[[3]] <- 4L
```

You can dig into the C code running this: 

```{r, eval=FALSE}
pryr::show_c_source(.Internal("[<-"))
```

## 2.4.1 Object size {-}

:::question
If I have two vectors, one `1:10` and another `c(1:10, 10)`, intuitively, I would expect the size of the second vector to be greater than the size of the first. However, it seems to be the other way round, why?
```{r}
x1 <- 1:10
x2 <- rep(1:10, 10)
lobstr::obj_size(x1)
lobstr::obj_size(x2)
```
:::

If we start with the following three vectors:
```{r}
x1 <- c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L)
x2 <- 1:10
x3 <- rep(1:10, 10)
lobstr::obj_sizes(x1, x2, x3)
```

Intuitively, we would have expected `x1` < `x2` < `x3` but this is not the case. It appears that the `rep()` function coerces a double into integer and hence optimizes on space. Using `:`, R internally uses [ALTREP](https://blog.revolutionanalytics.com/2017/09/altrep-preview.html). 

ALTREP would actually be more efficient if the numbers represented were significantly large, say `1e7`.

```{r}
x4 <- 1:1e7
x5 <- x4
x5[1] <- 1L
lobstr::obj_sizes(x4, x5)
```

Now, the size of x4  is significantly lower than that of x5 .  This seems to indicate that ALTREP becomes super efficient as the vector size is increased.

## 2.5.1 Modify-in-place {-}

:::question
"When it comes to bindings, R can currently only count 0, 1, or many. That means that if an object has two bindings, and one goes away, the reference count does not go back to 1: one less than many is still many. In turn, this means that R will make copies when it sometimes doesn’t need to."

Can we come up with an example of this? It seems really theoretical right now.
:::

First you need to switch your Environment tab to something other than global in RStudio!

Now we can create a vector:
```{r}
v <- c(1, 2, 3)
(old_address <- lobstr::obj_addr(v))
```

Changing a value within it changes its address:
```{r}
v[[3]] <- 4
(new_address <- lobstr::obj_addr(v))
old_address == new_address
```

We can assign the modified vector to a new name, where `y` and `v` point to the same thing.
```{r}
y <- v
(y_address <- lobstr::obj_addr(y))
(v_address <- lobstr::obj_addr(v))
y_address == v_address
```

Now if we modify `v` it won't point to the same thing as `y`:
```{r}
v[[3]] <- 3
(y_address <- lobstr::obj_addr(y))
(v_address <- lobstr::obj_addr(v))
y_address == v_address
```

But if we now change `y` to look like `v`, the original address, in theory editing y should occur in place, but it doesn't - the "count does not go back to one"!

```{r}
y[[3]] <- 3
(new_y_address <- lobstr::obj_addr(y))
new_y_address == y_address
```

:::question

Can we break down this code a bit more? I'd like to really understand when and how it's copying three times. **As of R 4.0 it's now copied twice, the 3rd copy that's external to the function is now eliminated!!**

```{r}
# dataframe of 5 columns of numbers
x <- data.frame(matrix(runif(5 * 1e4), ncol = 5))
# median number for each column
medians <- vapply(x, median, numeric(1))

# subtract the median of each column from each value in the column
for (i in seq_along(medians)) {
  x[[i]] <- x[[i]] - medians[[i]]
}
```
:::


```{r, eval=FALSE}
cat(tracemem(x), "\n")
```

```
<0x7fdc99a6f9a8> 
```

```{r, eval=FALSE}
for (i in 1:5) {
  x[[i]] <- x[[i]] - medians[[i]]
}
```

```
tracemem[0x7fdc99a6f9a8 -> 0x7fdc9de83e38]: 
tracemem[0x7fdc9de83e38 -> 0x7fdc9de83ea8]: [[<-.data.frame [[<- 
tracemem[0x7fdc9de83ea8 -> 0x7fdc9de83f18]: [[<-.data.frame [[<- 
tracemem[0x7fdc9de83f18 -> 0x7fdc9de83f88]: 
tracemem[0x7fdc9de83f88 -> 0x7fdc9de83ff8]: [[<-.data.frame [[<- 
tracemem[0x7fdc9de83ff8 -> 0x7fdc9de84068]: [[<-.data.frame [[<- 
tracemem[0x7fdc9de84068 -> 0x7fdc9de840d8]: 
tracemem[0x7fdc9de840d8 -> 0x7fdc9de84148]: [[<-.data.frame [[<- 
tracemem[0x7fdc9de84148 -> 0x7fdc9de841b8]: [[<-.data.frame [[<- 
tracemem[0x7fdc9de841b8 -> 0x7fdc9de84228]: 
tracemem[0x7fdc9de84228 -> 0x7fdc9de84298]: [[<-.data.frame [[<- 
tracemem[0x7fdc9de84298 -> 0x7fdc9de84308]: [[<-.data.frame [[<- 
tracemem[0x7fdc9de84308 -> 0x7fdc9de84378]: 
tracemem[0x7fdc9de84378 -> 0x7fdc9de843e8]: [[<-.data.frame [[<- 
tracemem[0x7fdc9de843e8 -> 0x7fdc9de84458]: [[<-.data.frame [[<- 
```

When we run `tracemem` on the for loop above we see each column is copied twice followed by the `[[<-.data.frame [[<- `, the stack trace showing exactly where the duplication occurred.

So what is ``[[<-.data.frame``? It's a function! By looking at `?``[[<-.data.frame`` we see this is used to "extract or replace subsets of data frames."

When we write `x[[i]] <- value`, it's really shorthand for calling the function `[[<-.data.frame` with inputs `x`, `i`, and `value`. 

Now let's step into the call of this base function by running `debug(``[[<-.data.frame``)`:

```{r, eval=FALSE}
debug(`[[<-.data.frame`)
```

and once inside, use `tracemem()` to find where the new values are assigned to the column:

```{r eval=FALSE}
function (x, i, j, value) 
{
  if (!all(names(sys.call()) %in% c("", "value"))) 
    warning("named arguments are discouraged")
  cl <- oldClass(x)
  # this is where another copy of x is made!
  class(x) <- NULL
```

```
 # tracemem[0x7fdc9d852a18 -> 0x7fdc9c99cc08]: 
```

```{r, eval = FALSE}
nrows <- .row_names_info(x, 2L)
  if (is.atomic(value) && !is.null(names(value))) 
    names(value) <- NULL
  if (nargs() < 4L) {
    nc <- length(x)
    if (!is.null(value)) {
      N <- NROW(value)
      if (N > nrows) 
        stop(sprintf(ngettext(N, "replacement has %d row, data has %d", 
          "replacement has %d rows, data has %d"), N, 
          nrows), domain = NA)
      if (N < nrows) 
        if (N > 0L && (nrows%%N == 0L) && length(dim(value)) <= 
          1L) 
          value <- rep(value, length.out = nrows)
        else stop(sprintf(ngettext(N, "replacement has %d row, data has %d", 
          "replacement has %d rows, data has %d"), N, 
          nrows), domain = NA)
    }
    x[[i]] <- value
    if (length(x) > nc) {
      nc <- length(x)
      if (names(x)[nc] == "") 
        names(x)[nc] <- paste0("V", nc)
      names(x) <- make.unique(names(x))
    }
    class(x) <- cl
    return(x)
  }
  if (missing(i) || missing(j)) 
    stop("only valid calls are x[[j]] <- value or x[[i,j]] <- value")
  rows <- attr(x, "row.names")
  nvars <- length(x)
  if (n <- is.character(i)) {
    ii <- match(i, rows)
    n <- sum(new.rows <- is.na(ii))
    if (n > 0L) {
      ii[new.rows] <- seq.int(from = nrows + 1L, length.out = n)
      new.rows <- i[new.rows]
    }
    i <- ii
  }
  if (all(i >= 0L) && (nn <- max(i)) > nrows) {
    if (n == 0L) {
      nrr <- (nrows + 1L):nn
      if (inherits(value, "data.frame") && (dim(value)[1L]) >= 
        length(nrr)) {
        new.rows <- attr(value, "row.names")[seq_len(nrr)]
        repl <- duplicated(new.rows) | match(new.rows, 
          rows, 0L)
        if (any(repl)) 
          new.rows[repl] <- nrr[repl]
      }
      else new.rows <- nrr
    }
    x <- xpdrows.data.frame(x, rows, new.rows)
    rows <- attr(x, "row.names")
    nrows <- length(rows)
  }
  iseq <- seq_len(nrows)[i]
  if (anyNA(iseq)) 
    stop("non-existent rows not allowed")
  if (is.character(j)) {
    if ("" %in% j) 
      stop("column name \"\" cannot match any column")
    jseq <- match(j, names(x))
    if (anyNA(jseq)) 
      stop(gettextf("replacing element in non-existent column: %s", 
        j[is.na(jseq)]), domain = NA)
  }
  else if (is.logical(j) || min(j) < 0L) 
    jseq <- seq_along(x)[j]
  else {
    jseq <- j
    if (max(jseq) > nvars) 
      stop(gettextf("replacing element in non-existent column: %s", 
        jseq[jseq > nvars]), domain = NA)
  }
  if (length(iseq) > 1L || length(jseq) > 1L) 
    stop("only a single element should be replaced")
  x[[jseq]][[iseq]] <- value
  # here is where x is copied again!
  class(x) <- cl
```

```
# tracemem[0x7fdc992ae9d8 -> 0x7fdc9be55258]: 
```
```{r, eval=FALSE} 
  x
}
```

Thus seeing exactly where the three **as of R 4.0: two!** copies are happening.

<!--chapter:end:02-names_and_values.Rmd-->

# Vectors

```{r, include=FALSE}
library(tidyverse)
library(kableExtra)
library(lobstr)
```

## 3.2.1 Scalars {-}

:::question
Can you have `NA` in vector
:::

Hell yeah!

## 3.2.3 Missing values {-}

:::question
`NA` is a 'sentinel' value for explicit missingness - what does 'sentinel' mean?
:::

A sentinel value (also referred to as a flag value, trip value, rogue value, signal value, or dummy data) is a special value in the context of an algorithm which uses its presence as a condition of termination. Also worth noting two NAs are not equal to each other! For instance, in C++ there’s a special character to identify the end of a string I think another example of a sentinel value might be in surveys where you sometimes see missing data or N/A coded as 999, or 9999 (or maybe just 9)


Another example of a sentinel value might be in surveys where you sometimes see missing data or `N/A` coded as `999`, or `9999` (or maybe just `9`). The possible values in a column of data might be:

```{r eval=FALSE}
factor(c(1,1,1,1,2,3,3,4,4,9), levels = c(1,2,3,4,9))
```

Sentinels are typically employed in situations where it's easier/preferable to have a collection of values of the same type - represented internally using the same conventions and requiring the same amount of memory - but you also need a way to indicate a special circumstance. So like in the case of survey data you may, for example, see a variable indicating that an individual is `999` years old but the correct way to interpret that is that the data was not collected.

## 3.2.4 Testing and coercion {-}

:::question
Why does the book warn us against using `is.vector()`, `is.atomic()` and `is.numeric()`? [read docs]
:::

- `is.atomic` will also return true if `NULL`
- `is.numeric` tests if integer or double **NOT** factor, Date, POSIXt, difftime
- `is.vector` will return false if it has attributes other than names

## 3.3.1 Setting Attributes {-}

:::question
Working in the medical field I have to import SAS files a lot where the column names have to adhere to specific abbreviations so they're given a label attribute for their full name. What are some other common uses for attributes?
:::

Hypothesis test attributes!


## 3.3.2 setNames {-}

:::question
We can use `setNames` to apply different values to each element in a vector. How do we do this for our own custom attribute? The code below does NOT work!

```{r}
my_vector <- c(
  structure(1, x = "firstatt_1"),
  structure(2, x = "firstatt_2"), 
  structure(3, x = "firstatt_3")
)

my_vector <- setNames(my_vector, c("name_1", "name_2", "name_3"))

# mental model: shouldn't this should return $names and $x?
attributes(my_vector)
```
:::

As soon as you instantiate a vector the attributes are lost. BUT we can store it as a list *within* the vector to keep them! We can create a custom attribute function and use that with `map` to add a list inside our dataframe:

```{r}
custom_attr <- function(x, my_attr) {
  attr(x, "x") <- my_attr
  return(x)
}

as_tb <- 
  tibble(
  one = c(1,2,3),
  x = c("att_1", "att_2", "att_3"),
  with_arr = map2(one, x, ~custom_attr(.x, .y))
)

as_tb$with_arr
```

## 3.3.3 Dimensions {-}

:::question
Because `NROW` and `NCOL` don't return `NULL` on a one dimensional vector they just seem to me as a more flexible option. When do you *have* to use `ncol` and `nrow`?
:::

It *may* be better practice to always use `NROW` and `NCOL`!

:::question
As long as the number of rows matches the data frame, it’s also possible to have a matrix or array as a column of a data frame. (This requires a slight extension to our definition of a data frame: it’s not the `length()` of each column that must be equal, but the `NROW()`.)

```{r}
df <- data.frame(x = c(1,2,3,4,5),
                 y = c(letters[1:5]))

length(df$y) == NROW(df$y)
```

What's an example of where `length() != NROW()`
:::

The case of a matrix! 

```{r}
my_matrix <- 1:6
dim(my_matrix) <- c(3,2)
my_matrix
length(my_matrix) == NROW(my_matrix) # 6 != 3
length(my_matrix) == NCOL(my_matrix) # 6 != 2
```

The length of the matrix is `6`, and if we manipulate the dimensions of the matrix we see that the NROW is `3` and and NCOL is `2`.

## 3.4 S3 atomic vectors {-}

:::question
How is data type `typeof()` different from `class()`?
:::

Classes are built on top of base types - they're like special, more specific kinds of types. In fact, if a class isn't specified then `class()` will default to either the `implicit class` or `typeof`.

So `Date`, `POSIXct`, and `difftime` are specific kinds of doubles, falling under its umbrella.
```{r}
lubridate::is.Date(Sys.Date())
is.double(Sys.Date())

lubridate::is.POSIXct(Sys.time())
is.double(Sys.time())

lubridate::is.difftime(as.difftime(c("0:3:20", "11:23:15")))
is.double(as.difftime(c("0:3:20", "11:23:15")))
```

But then why does `my_factor` fail to be recognized under its more general `integer` umbrella?

```{r}
my_factor <- factor(c("a", "b", "c"))
is.factor(my_factor)
is.integer(my_factor)
```

:::TODO
XXX
:::

## 3.4.2 Dates {-}

:::question
Why are dates calculated from January 1st, 1970?
:::

Unix counts time in seconds since its official "birthday," -- called "epoch" in computing terms -- which is Jan. 1, 1970. [This article](https://www.wired.com/2001/09/unix-tick-tocks-to-a-billion/) explains that the early Unix engineers picked that date arbitrarily, because they needed to set a uniform date for the start of time, and New Year's Day, 1970, seemed most convenient.


## 3.5.1 Lists {-}

:::question
When should you be using `list()` instead of `c()`
:::

It's really contingent on the use case. In the case of adding custom classes it's worth noting that those are lost once you `c()` those objects together!

## 3.6.8 Data frames and tibbles {-}

:::question
What does 'lazy' mean in terms of `as_tibble`?
:::
  
Technically `lazy evaluation` means that expressions are not evaluated when they are bound to variables, but their evaluation is deferred until their results are needed by other computations. In this context though we think Hadley just meant that it's treated as a character if it "looks and smells like a character". 


:::question
The solution manual gives the answer and notes:

```{r}
df_coltypes <- data.frame(
  a = c("a", "b"),
  b = c(TRUE, FALSE),
  c = c(1L, 0L),
  d = c(1.5, 2),
  e = c("one" = 1, "two" = 2),
  g = factor(c("f1", "f2")),
  stringsAsFactors = FALSE
)

as.matrix(df_coltypes)
```

"Note that `format()` is applied to the characters, which gives surprising results: `TRUE` is transformed to `" TRUE"` (starting with a space!)."

...But where is the `format()` call happening? I don't see a space!
:::

After running `debug(as.matrix(df_coltypes))` and going down a rabbit hole we found this is a bug that has been addressed! [See issue here](https://github.com/Tazinho/Advanced-R-Solutions/issues/213)

## Conclusion {-}

:::question
How does vectorization make your code faster
:::

Taking the example from [Efficient R Programming](https://csgillespie.github.io/efficientR/programming.html#vectorised-code):

### VECTORIZED: {-}
```{r, eval=FALSE}
sum(log(x))
```

### NON-VECTORIZED: {-}
```{r, eval=FALSE}
s <- 0
for(x0 in x) {
  s <- s + log(x0)
}
```

The vectorized code is faster because it obeys the golden rule of R programming: *"access the underlying C/Fortran routines as quickly as possible; the fewer functions calls required to achieve this, the better"*. 

- Vectorized Version:
  1. `sum` [called once]
  2. `log` [called once]
  
- Non-vectorized:
  1. `+` [called `length(x)` times]
  2. `log` [called `length(x)` times]

In the vectorised version, there are two primitive function calls: one to `log` (which performs `length(x)` steps in the C level) and one to `sum` (which performs `x` updates in the C level). So you end up doing a similar number of operations at C level regardless of the route. 

In the non-vectorised form you are passing the logic back and forth between R and C many many times and this is why the non-vectorised form is much slower.

**A vectorized function calls primitives directly, but a loop calls each function `length(x)` times, and there are `1 + length(x)` assignments to `s`. Theres on the order of 3x primitive function calls in the non-vectorised form!!**

Resources:

- [Check out Jenny Brian's slides](https://speakerdeck.com/jennybc/row-oriented-workflows-in-r-with-the-tidyverse)

- [Great article by Noam Ross](https://www.noamross.net/archives/2014-04-16-vectorization-in-r-why/)

:::question
Putting it all together in a single diagram:
:::

```{r, echo=FALSE}
knitr::include_graphics("images/vectors.png")
```

<!--chapter:end:03-vectors.Rmd-->

# Subsetting

```{r, include=FALSE}
library(tidyverse)
library(kableExtra)
library(lobstr)
```

## 4.1 Introduction {-}

:::question
"There are three subsetting operators `[`. `[[`, `$`. What is the distinction between an operator and a function? When you look up the help page it brings up the same page for all three extraction methods. What are their distinctions and do their definitions change based on what you're subsetting? Can we make a table? 
:::

```{r, echo=FALSE}
subsetting_table <- tibble(
  names = c("ATOMIC", "LIST", "MATRIX", "DATA FRAME", "TIBBLE"),
  
  `[` = c("RETURNS VECTOR WITH ONE ELEMENT",
          "RETURNS A LIST",
          "RETURNS A VECTOR",
          "RETURNS A VECTOR OR DATA FRAME",
          "RETURNS A TIBBLE"
   ),
  
  `[[` = c("SAME AS [", 
           "RETURNS SINGLE ELEMENT FROM WITHIN LIST",
           "RETURNS A VECTOR OR SINGLE VALUE",
           "RETURNS VECTOR/LIST/MATRIX OR SINGLE VALUE",
           "RETURNS A VECTOR OR SINGLE VALUE"
    
  ),
  
  `$` = c(
    "NOPE!",
    "RETURN SINGLE ELEMENT FROM LIST [CAN ONLY USE WHEN LIST VECTOR HAS A NAME]",
    "NOPE!",
    "RETURNS VECTOR/LIST/MATRIX USING COLUMN NAME",
    "RETURNS THE STR OF THE COLUMN - TIBBLE/LIST/MATRIX"
  )
) %>%
  column_to_rownames("names")

kableExtra::kable(subsetting_table)
```

If we think of everything as sets (which have the properties of 0,1, or many elements), if the set has 1 element it only contains itself and `NULL` subsets. Before you subset using `[` or `[[` count the elements in the set. If it has zero elements you are done, if it has one element `[` will return itself - to go further you need to use `[[` to return its contents. If there is more than one element in the set then `[` will return those elements. [You can read more about subsetting here](https://bookdown.org/rdpeng/rprogdatascience/subsetting-r-objects.html#subsetting-a-vector)

## 4.2.1 Selecting multiple elements {-}

:::question
Why is `numeric(0)` "helpful for test data?"
:::

This is more of a general comment that one should make sure one's code doesn't crash with vectors of zero length (or data frames with zero rows)

:::question
Why is subsetting with factors "not a good idea"
:::

Hadley's notes seem to say subsetting with factors uses the "integer vector of levels" - and if they all have the same level, it'll just return the first argument. Subsetting a factor vector leaves the factor levels behind unless you explicitly drop the unused levels

## 4.2.2 lists {-}

:::question
We've been talking about `$` as a shorthand for `[[`. Using the example list `x <- list(1:3, "a", 4:6)` can we use `x$1` as shorthand for `x[[1]]`?
:::

The "shorthand" refers to using the name of the vector to extract the vector. If we give `1:3` a name such as test = `1:3`

```{r}
x <- list(named_vector = 1:3, "a", 4:6)
x[[1]] == x$named_vector
```

As such, `$` is a shorthand for `x[["name_of_vector"]]` and not shorthand for `x[[index]]`

## 4.3.1 `[[` {-}

:::question

The book states: 

*While you must use [[ when working with lists, I’d also recommend using it with atomic vectors whenever you want to extract a single value. For example, instead of writing:*

```{r, eval=FALSE}
for (i in 2:length(x)) {
  out[i] <- fun(x[i], out[i - 1])
}
```

*It's better to write*

```{r, eval=FALSE}
for (i in 2:length(x)) {
  out[[i]] <- fun(x[[i]], out[[i - 1]])
}
```

Why? Can we see this in action by giving `x`, `out`, and `fun` real life values?
:::

If we have a vector
```{r}
df_x <- c("Advanced","R","Book","Club")
```

We can use `[` or `[[` to extract the third element of `df_x`
```{r}
df_x[3]
df_x[[3]]
```

But in the case where we want to extract an element from a list `[` and `[[` no longer give us the same results
```{r}
df_x <- list(A = "Advanced", B = "R", C = "Book", D = "Club")

df_x[3]
df_x[[3]]
```

Because using `[[` returns "one element of this vector" in both cases, it makes sense to default to `[[` instead of `[` since it will reliably return a single element. 

## 4.3.5 Exercise {-}

:::question
The question asks to describe the `upper.tri` function - let's dig into it!
:::

```{r}
x <- outer(1:5, 1:5, FUN = "*")
upper.tri(x)
```

We see that it returns the upper triangle of the matrix. But I wanted to walk through how this function actually works and what is meant in the solution manual by leveraging `.row(dim(x)) <= .col(dim(x))`.

```{r, eval=FALSE}
# ?upper.tri
function (x, diag = FALSE) 
{
    d <- dim(x)
    # if you have an array thats more than 2 dimension
    # we need to flatten it to a matrix
    if (length(d) != 2L) 
        d <- dim(as.matrix(x))
    if (diag) 
      # this is our subsetting logical!
         .row(d) <= .col(d)
    else .row(d) < .col(d)
}
```

The function `.row()` and `.col()` return a matrix of integers indicating their row number

```{r}
.row(dim(x))
```

```{r}
.col(dim(x))
```

```{r}
.row(dim(x)) <= .col(dim(x))
```


:::question
Is there a high level meaning to a `.` before function? Does this refer to internal functions? [see: ?`row` vs ?`.row`]
:::

Objects in the global environment prefixed with `.` are hidden in the R (and RStudio) environment panes - so functions prefixed as such are not visible unless you do `ls(all=TRUE)`. [Read more here](https://community.rstudio.com/t/function-argument-naming-conventions-x-vs-x/7764) and (here)[https://stackoverflow.com/questions/7526467/what-does-the-dot-mean-in-r-personal-preference-naming-convention-or-more]

## 4.3.3 Missing and OOB {-}

:::question
Let's walk through examples of each
:::

### LOGICAL ATOMIC {-}

```{r, eval=FALSE}
c(TRUE, FALSE)[[0]] # zero length
# attempt to select less than one element in get1index <real>
c(TRUE, FALSE)[[4]] # out of bounds
# subscript out of bounds
c(TRUE, FALSE)[[NA]] # missing
# subscript out of bounds
```

### LIST {-}
```{r, eval=FALSE}
list(1:3, NULL)[[0]] # zero length
# attempt to select less than one element in get1index <real>
list(1:3, NULL)[[3]] # out of bounds
# subscript out of bounds
list(1:3, NULL)[[NA]] # missing
# NULL
```

### NULL {-}

```{r, eval=FALSE}
NULL[[0]] # zero length
# NULL
NULL[[1]] # out of bounds
# NULL
NULL[[NA]] # missing
# NULL
```

## 4.5.8 Logical subsetting {-}

:::question
"Remember to use the vector Boolean operators `&` and `|`, not the short-circuiting scalar operators `&&` and `||`, which are more useful inside if statements." 

Can we go over the difference between `&` and `&&` (and `|` vs `||`) I use brute force to figure out which ones I need...
:::

`&&` and `||` only ever return a single (scalar, length-1 vector) `TRUE` or `FALSE` value, whereas `|` and `&` return a vector after doing element-by-element comparisons.

The only place in R you routinely use a scalar `TRUE`/`FALSE` value is in the conditional of an `if` statement, so you'll often see `&&` or `||` used in idioms like: `if (length(x) > 0 && any(is.na(x))) { do.something() }`

In most other instances you'll be working with vectors and use `&` and `|` instead.

Using `&&` or `||` results in some unexpected behavior - which could be a big performance gain in some cases:

- `||` will not evaluate the second argument when the first is `TRUE`
- `&&` will not evaluate the second argument when the first is `FALSE`

```{r}
true_one <- function() { print("true_one evaluated."); TRUE}
true_two <- function() { print("true_two evaluated."); TRUE}
# arguments are evaluated lazily.  Unexpected behavior can result:
c(T, true_one()) && c(T, true_two())
c(T, true_one()) && c(F, true_two())
c(F, true_one()) && c(T, true_two()) 
c(F, true_one()) && c(F, true_two()) 
c(T, true_one()) || c(T, true_two())
c(T, true_one()) || c(F, true_two())
c(F, true_one()) || c(T, true_two()) 
c(F, true_one()) || c(F, true_two()) 
```

Read more about [Special Primatives](https://cran.r-project.org/doc/manuals/r-release/R-ints.html#Special-primitives) here

## 4.5.8 Boolean algebra {-}

:::question
The `unwhich()` function takes a boolean and turns it into a numeric - would this ever be useful? How?
:::

:::TODO
XXX
:::

:::question
"`x[-which(y)]` is not equivalent to `x[!y]`: if `y` is all FALSE, `which(y)` will be `integer(0)` and `-integer(0)` is still `integer(0)`, so you’ll get no values, instead of all values."

Can we come up with an example for this plugging in values for `x` and `y`
:::

```{r}
c(TRUE, FALSE)[-which(FALSE)]
c(TRUE, FALSE)[!FALSE]
```

<!--chapter:end:04-subsetting.Rmd-->

# Control Flow

```{r, include=FALSE}
library(tidyverse)
library(kableExtra)
library(lobstr)
```

## 5.2.2 Vectorised if {-}

:::question
Why does `if` `else` print `"Out of range"` once but `ifelse` prints it twice?

```{r, eval=FALSE}
if (sample(1:10, 1) == 1) print("In range") else print("Out of range")
```

```
[1] "Out of range"
```

```{r, eval=FALSE}
ifelse((sample(1:10, 1) == 1), print("In range"), print("Out of range"))
```

```
[1] "Out of range"
[1] "Out of range"
```
:::

```{r, eval=FALSE}
var <- if (sample(1:10, 1) == 1) print("In range")
var
```

```
NULL
```

```{r}
var <- ifelse((sample(1:10, 1) == 1), print("In range"), print("Out of range"))
var
```

`ifelse` explicitly returns its result, whereas `if` invisibly returns it!

```{r}
ifelse(c(TRUE, FALSE, TRUE), 1:2, 3)
```

Honestly, `ifelse()` is weird. Try this too:

```{r}
ifelse(c(TRUE, FALSE, TRUE), 1:10, 3)
```

## 5.3 Loops  {-}

:::question
Can the body of the loop change the set?
:::

```{r}
my_set <- c(1, 20, 99)

for (i in my_set){
  if (i==1){
    my_set[9]= 20
    }
  print("hello")
  print(my_set)
  }
```
Looks like you can't!

## 5.2.3 switch statement {-}

:::question
"Closely related to if is the `switch()` statement. It’s a compact, special purpose equivalent"

What is meant here by "special purpose"? Can we come up with a case where you can't substitute `if` for `switch` or the other way around? Use `switch`. Is it safe to say to `switch` when you have character inputs (as the book suggests) and use `case_when` or `if` for numerics?
:::

Switch is special in that only ONE value can be true, as in the case from our presentation the shiny input can only ever be ONE of the strings on the left it cannot be multiple.

```{r, eval=FALSE}
datasetInput <- reactive({ 
  switch(input$dataset,
         "materials" = brewing_materials,
         "size" = brewer_size,
         "states" = beer_states,
         "taxed" = beer_taxed)
})
```


## 5.3.1 common pitfalls {-}

:::question
What does the book mean by leveraging `vector` for preallocating the loop output? How is this different from creating an empty list to instantiate the loop? 

```{r}
means <- c(1, 50, 20)

out_vector <- vector("list", length(means))
for (i in 1:length(means)) {
  out_vector[[i]] <- rnorm(10, means[[i]])
}

out_list <- list()
for (i in 1:length(means)) {
  out_list[[i]] <- rnorm(10, means[[i]])
}
```
:::

By preallocating the length of the `out_vector` we're leveraging `modify-in-place` rather than `copy-on-modify`.

:::question
The book warns against using `length(x)` and suggests using `seq_along` instead. Is there any downside to using `seq_along` or a case when you'd prefer `length(x)` over `seq_along(x)`? I can't think of any downsides to using it!
:::

:::TODO
We have yet to find a downside but should look into this further!
:::

## 5.3.3.1 Exercises {-}

:::question
```{r}
x <- numeric()
out <- vector("list", length(x))
for (i in 1:length(x)) {
  out[i] <- x[i] ^ 2
}
out
```

I understand that this works because we can count down in a loop - so the first iteration `x[1] == NA`, and the second `x[2] == numeric(0)` but where does this value go? Is it just evaluated but not stored since R counts from 1?
:::

This question is actually the bigger question, "Can you assign something to index 0 in R?" and it doesn't seem that you can.


### Assignment to a valid index {-}

```{r}
mylist = list()
mylist[1] <- c("something")
mylist[1]
```

### Assignment to [0] {-}

```{r}
mylist = list()
mylist[0] <- c("something")
mylist[0]
```

It's interesting that it's syntactically correct to assign to `mylist[0]`  but it does nothing!

### Empty index {-}

```{r}
mylist = list()
mylist[1]
```

R defaultly accesses the first layer using `[` and says there are no elements in the first layer of `mylist` and returns `NULL`. But when you do `mylist[[1]]` R says `Out of Bounds` because the first layer of `mylist` has been called and there is no layer at all. That's why R throws error in `[[` case.

### Impossible Index `[[` {-}

```{r, eval=FALSE}
mylist = list()
mylist[[0]]
```

```
Error in mylist[[0]] : attempt to select less than one element in get1index <real>
```

`[[` isolates one element whereas `[` can be used to get subsets of varying sizes.
`[[` gets precisely one element, no more no less, or it fails. So `[[0]]<-` cannot work because index zero cannot hold a value. 

### Impossible Index `[[<-`  {-}

```{r, eval=FALSE}
mylist = list()
mylist[[0]] <- "something"
```

```
Error in mylist[[0]] <- "something" : attempt to select less than one element in integerOneIndex
```

### Undefined name {-}

Selection using an undefined - but possible name - gives NULL

```{r, eval=FALSE}
mylist = list()
mylist[["undefined_name"]]
```

### Out of Bounds {-}

Selection using a possible - but not currently allocated - index gives an out of bounds error

```{r, eval=FALSE}
mylist = list()
mylist[[10]]
```

```
Error in mylist[[10]] : subscript out of bounds 
```

## Conclusion {-}

:::question
Can we put these concepts together in diagram form? Let's work on improving these schematics!
:::

Let's first put functions into words:


* If condition then run code, else quit
* A vectorized version of: if condition then run code, else run other code
* For every element in list of elements do what is in between the curly braces
* While this condition is true do this
* Repeat this until something tells you to break out

```{r, echo=FALSE}
knitr::include_graphics("images/controlflow.png")
```

We can visualize how the `ifelse` logic on a single element above will operate on each element within a vector:

```{r, echo=FALSE, fig.align='center'  }
knitr::include_graphics("images/ifelse.png")
```

For instance if we can run:

```{r}
ifelse(c(TRUE, FALSE, TRUE), 1:2, 3)
```

Lets break down what's happening:


Create a test answer:
```{r}
test <- c(TRUE, FALSE, TRUE)
yes <- 1:2
no <- 3
```

which indices in the test are TRUE and which are FALSE
```{r}
yes_idx <- which(test) # 1,3
no_idx <- which(!test) # 2
```

set up our answer
```{r}
answer <- test # T, F, T
```

grow the yes and no answers to the length of the test (input)
```{r}
yes_final <- rep(yes, length.out = length(test))
no_final <- rep(no, length.out = length(test))
```

fill the answer with yes or no from the enlarged yes/no answers
```{r}
answer[yes_idx] <- yes_final[yes_idx]  # 1,1
answer[no_idx] <- no_final[no_idx]     # 3
```

return our final answer:

```{r}
answer
```


Another example: we can run 
```{r}
ifelse(c(TRUE, FALSE, TRUE, FALSE, TRUE, TRUE), 1:10, "FALSE")
```

we can see that ifelse places the numbers in `1:10` based on their index where our condition is to `TRUE` and inserts the string `"FALSE"` whenever the condition is `FALSE`

## Complexity {-}

Cyclomatic complexity is a software metric used to indicate the complexity of a program. It is computed using the control flow graph of the program: the nodes of the graph correspond to indivisible groups of commands of a program, and a directed edge connects two nodes if the second command might be executed immediately after the first command. 

We can use the package `cyclocomp` to look at the cyclomatic complexity of functions. Looking at each function from the Chapter 5 presentation:

```{r, echo=FALSE}
library(cyclocomp)

if_func <- function(x) {
  if (sample(beer_states$state, 1) == "NV") print("My Home State")
}

if_else_func <- function(x) {
  if (sample(beer_states$state, 1) == "NV") print("My Home State") else print("Not my home")
}

ifelse_func <- function(x) {
  ifelse((sample(beer_states$state, 1) == "NV"), print("My Home State"), print("Not my home"))
}

casewhen_func <- function(x) {
  dplyr::case_when(
  barrels >= 100000000 ~ "A LOT!",
  barrels >= 10000000 ~ "Many",
  barrels >= 1000000 ~ "A few",
  TRUE ~ "Not much"
)
}

switch_func <- function(x) {
  switch(x,
         "materials" = brewing_materials,
         "size" = brewer_size,
         "states" = beer_states,
         "taxed" = beer_taxed)
}

for_func <- function(x) {
  for (i in 1:nrow(beer_states)) { #<<
  if (beer_states$state[i] %in% Region1) {
    beer_states$region[i] <- "Region 1"
  } else if (beer_states$state[i] %in% Region2) {
    beer_states$region[i] <- "Region 2"
  } else if (beer_states$state[i] %in% Region3) {
    beer_states$region[i] <- "Region 3"
  } else if (beer_states$state[i] %in% Region4) {
    beer_states$region[i] <- "Region 4"
  } else if (beer_states$state[i] %in% Region5) {
    beer_states$region[i] <- "Region 5"
  } else if (beer_states$state[i] %in% Region6) {
    beer_states$region[i] <- "Region 6"
  } else if (beer_states$state[i] %in% Region7) {
    beer_states$region[i] <- "Region 7"
  } else if (beer_states$state[i] %in% Region8) {
    beer_states$region[i] <- "Region 8"
  } else if (beer_states$state[i] %in% Region9) {
    beer_states$region[i] <- "Region 9"
  } else if (beer_states$state[i] %in% Region10) {
    beer_states$region[i] <- "Region 10"
  } else {
    beer_states$region[i] <- "Missing"
  }
  }
}

while_func <- function(x) {
  i <- 0
  my_vector <- vector()
  while (i <= input$xqty) {
    my_vector[i] <- i
    i = i+1
  }
  return(my_vector)
}

repeat_func <- function(x) {
  repeat {   
    if (sample(beer_states$state, 1) == "NV") {
      print("Go grab a beer!");
      break
    } else print("Maya doesn't live here");
  }
}
```

```{r}
controlflow_functions <- list(
  if_func = if_func,
  if_else_func = if_else_func,
  ifelse_func = ifelse_func,
  casewhen_func = casewhen_func,
  switch_func = switch_func, 
  for_func = for_func,
  while_func = while_func,
  repeat_func = repeat_func)

purrr::map_df(controlflow_functions, cyclocomp)
```

We see that the `for` loop was our most complex function and `while` had a complexity of 3. The rest of our functions had a complexity of `1`. 

As [Colin Fay states](https://engineering-shiny.org/successfulshinyapp.html): 

"Splitting a complex function into smaller functions is not a magic solution because (A) the global complexity of the app is not lowered by splitting things into pieces (just local complexity), and (B) the deeper the call stack, the harder it can be to debug."

<!--chapter:end:05-control_flow.Rmd-->

# Functions

```{r, include=FALSE}
library(tidyverse)
library(kableExtra)
library(lobstr)
library(rlang)
```

## 6.2.2 Primitives {-}

:::question
So if you are familiar with C can you just write a function in C *in* R? What does that process look like? I think this is a bigger question of digging into the relationship between C and R.
:::

We can use RCPP!

```{r}
Rcpp::cppFunction('#include<string>
  std::string IPA() {
  std::string val = "IPAs suck";	
  return val;
  }')
val <- IPA()
val
```

## 6.2.5.1 Exercises {-}

:::question
[This question is flagged as "started" let's try to complete it!](https://github.com/Tazinho/Advanced-R-Solutions/blob/5043d9b06c7469a010c568ecb85e12bedca75207/2-06-Functions.Rmd#L9)
:::

1. __[Q]{.Q}__: Given a name, like `"mean"`, `match.fun()` lets you find a function. Given a function, can you find its name? Why doesn't that make sense in R?

    __[A]{.started}__: A name can only point to a single object, but an object can be pointed to by 0, 1, or many names. What are names of the functions in the following block?

    ```{r}
  function(x) sd(x) / mean(x)
    
  f1 <- function(x) (x - min(x)) / (max(x) - min(x))
  f2 <- f1
  f3 <- f1
    ```

:::TODO
XXX
:::

## 6.3 Function composition {-}

:::question
When comparing nested, intermediate, and piping functions, it looks like Hadley flips the order of `f()` and `g()` between bullet points
:::

It does look like he does that!


```{r}
f <- function(z) {
  cat("g is:", z)
}

g <- function(x) {
  x * 2
}
```

### Nested

```{r}
f(g(2))
```

### Intermediate 

This is written in the book as `y <- f(x); g(y)` but should be flipped to `y <- g(x); f(y)` if we are to follow the nested example

```{r}
y <- g(2)
f(y)
```

### Piping

This also needs to be flipped from `x %>% f() %>% g()` to `x %>% g() %>% f()`

```{r}
2 %>% g() %>% f()
```


## 6.4 Lexical scoping {-}

:::question
"The scoping rules use a parse-time, rather than a run-time structure"? What is "parse-time" and "run-time"? How do they differ?
:::

parse-time is when the function gets defined: when the formals and body get set. run-time is when it actually gets called. This function doesn't get past parse-time because of the syntax error

```{r, eval=FALSE}
get_state <- function(in_df, state_name){
  out_df % in_df[in_df$state == state_name, ]
  return(out_df)
}
```

```
get_state <- function(in_df, state_name){
  out_df % in_df[in_df$state == state_name, ]

Error: unexpected input in:

"get_state <- function(in_df, state_name){
  out_df % in_df[in_df$state == state_name, ]"
  return(out_df)

Error: object 'out_df' not found
}

Error: unexpected '}' in "}"
```

This function will get parsed successfully but could fail at run at run-time if the input data frame doesn't have a column named state:

```{r}
get_state <- function(in_df, state_name){
  out_df <- in_df[in_df$state == state_name, ]
  return(out_df)
}  

get_state(iris, 'setosa')
```

At R's build-time, if you want to run a function from a package that isn't loaded it will not throw an error but at run-time it will if the required package is not loaded:

```{r}
func_1 <- function(df, x) {
  select({{ df }}, {{ x }})
}

test_tbl <- tibble::tibble(x1 = runif(5),
             x2 = rnorm(5),
             x3 = rpois(5, lambda = 1))
```

Without `dplyr` this will fail
```{r, eval=FALSE}
func_1(test_tbl, x1)
```

```
Error in select({: could not find function "select"
```

This will work:
```{r}
library(dplyr)
#> 
#> Attaching package: 'dplyr'
#> The following objects are masked from 'package:stats':
#> 
#>     filter, lag
#> The following objects are masked from 'package:base':
#> 
#>     intersect, setdiff, setequal, union
func_1(test_tbl, x1)
```


## 6.4.3 A fresh start {-}

:::question
How would we change this code so that the second call of `g11()` is 2?

```{r}
g11 <- function() {
  if (!exists("a")) {
    a <- 1
  } else {
    a <- a + 1
  }
  a
}

g11()
```
:::

```{r}
g11 <- function() {
  if (!exists("a")) {
    a <- 1
  } else {
    a <- a + 1
  }
  a <<- a
  a
}

g11()
```


##  6.5 Lazy evaluation {-}

:::question
"This allows you to do things like include potentially expensive computations in function arguments that will only be evaluated if needed"

Does anyone have an example of this? We discussed a function that will only perform expensive tasks given the context of the function perhaps?
:::

Maybe a situation where we can give a function default arguments where `sample`is a stand in for longer expensive functions like different fancy modeling techniques? We can workshop this...

```{r}
mega_model <- function(values, x = sample(1:100, 10), y = sample(200:300, 10), z = sample(300:400, 10)
) {
  dplyr::case_when(
    is.numeric(values) ~ x,
    is.character(values) ~ y,
    TRUE ~ z
  )
}

mega_model(c("a", "b", "c"))
```



## 6.5.1 Promises {-}

:::question
Can we discuss the order that this happening in? Is it that `Calculating...` is printed, then `x*2` then `x*2` again? I am still reading this as: `h03(double(20), double(20))` which is an incorrect mental model because the message is only printed once...

```{r}
double <- function(x) { 
  message("Calculating...")
  x * 2
}

h03 <- function(x) {
  c(x, x)
}
```
:::


:::TODO

Still need to work on explaining what's happening here and what that would look like graphically:

```{r}
double <- function(y) {
  message("Calculating...")
  cat("double before\n")
  print(pryr::promise_info(y))
  force(y)
  cat("double after\n")
  print(pryr::promise_info(y))
  y * 2
}
h03 <- function(x) {
  cat(paste0("h03 before\n"))
  print(pryr::promise_info(x))
  force(x)
  cat("h03 after\n")
  print(pryr::promise_info(x))
  c(x, x)
}
double(h03(20))
```

```{r, echo=FALSE, fig.align='center'}
knitr::include_graphics("images/promise.png")
```
:::


:::question
```{r}
plop <- function(a, b) a * 10
plop(2, var_doesnt_exist)
```

`var_doesnt_exist` is a promise within `g`, we use the promises within `g` when we call `f` but `f` never uses its second argument so this runs without a problem. When would we want to leverage this behavior?
:::

The unevaluated `var_doesnt_exist` doesn’t exist , but we can use `substitute` to to get the expression out of a promise! If we modify our function we can play with the expression contained in b:

```{r}
plop <- function(a, b) {
  cat("You entered", deparse(substitute(b)), "as `b` \n")
  a * 10
}
plop(a = 2, b = var_doesnt_exist)
```

We can even evaluate `b` and use it to create a `dplyr` like `pull` function:

```{r}
plop <- function(a, b) {
  eval(substitute(b), envir = a)
}
plop(iris, Species)[1:10]
```


## 6.5.2 Default arguments {-}

:::question
I don't quite understand why `x = ls()` is different from `ls()` here; aren't we still assigning `x = ls()` but without specifying x?
```{r}
h05 <- function(x = ls()) {
  a <- 1
  x
}

# this makes sense to me
h05()
# how is this different from above?
h05(ls())
```
:::

The difference is where the promise is created. `ls()` is always evaluated inside `h05` when `x` is evaluated. The difference is the environment. When `ls()` is provided as an explicit parameter, `x` is a promise whose environment is the global environment. When `ls()` is a default parameter, it is evaluated in the local environment where it is used.

Hypothesis: does nesting `ls()` in `h05` first evaluate `ls()` then evaluate `h05()` ?

```{r, eval=FALSE}
library(magrittr)
h05 <- function(x = {y <- 4;ls()}) {
   a <- 1
   x
}
```

```{r, eval=FALSE}
h05()
```

```
[1] "a" "x" "y"
```

```{r, eval=FALSE}
ls()
```

```
[1] "h05"
```

```{r, eval=FALSE}
{y <- 4;ls()} %>% h05()
```

```
[1] "h05" "y"  
```

```{r, eval=FALSE}
ls()
```

```
[1] "h05" "y" 
```

```{r, eval=FALSE}
h05({x <- 5;ls()})
```

```
[1] "h05" "x"   "y" 
```

```{r, eval=FALSE}
ls()
```
```
[1] "h05" "x"   "y" 
```

Notice in all of the latter calls, a is not returned - so it's not evaluating `ls()` inside of the function.

## 6.5.4.3 Exercise {-}

:::question

I understand this problem is showing us an example of name masking (the function doesn't need to use the `y = 0` argument because it gets `y` from within the definition of x, but I'm fuzzy on what exactly the `;` does. What does the syntax `{y <- 1; 2}` mean? Could it be read as "Set `y <- 1` and `x <- 2`?

```{r}
y <- 10
f1 <- function(x = {y <- 1; 2}, y = 0) {
  c(x, y)
}
f1()
```
:::

The curly brackets are an expression, which can be read as 

```{r}
{
  y <- 1
  2
}
```

This is returning `2` and setting `1` to `y`. The colon can be read as a new line in the expression. `x` is called inside the function and overwrites the argument value of `y`

```{r}
f1 <- function(x = {y <- 1; 2}, y = 0) {
  # At this point, neither x nor y have been needed or evaluated. This is "lazy".
  cat(y) 
  # "Summon the current state of y". 
  # R looks first in the function env - is there a y there? No
  # R then looks at the arguments - is there a y there? Yes, it's 0 -> print out zero 
  # If R had not found y in the arguments, then it would look in the parent environment of the function - the global env.
  # That's where it would find y = NULL - but since it already found a default arg, it already stopped evaluating. 
  cat(x)
  # "Summon the current state of x"
  # x is an expression that first sets y to equal 1 and then returns the number 2 -> print out 2
  c(x, # "Summon the current state of x" - x is still the expression that sets y to 1 and then x to 2
    y) # "Summon the current state of y" - y was set to 1, so y is 1 here.
}
f1()
```

Compare to:

```{r}
f1 <- function(x = {y <- 1; 2}, y = 0) {
  c(y, # "Summon the current state of y" - y has not yet been set to anything else, so it returns zero
    x) # "Summon the current state of x" - x is still the expression that sets y to 1 and then x to 2
       # However, y has already been returned - so even though y is now set to 1, it's called after the previous y and does not affect the previous y.
}
x = NULL
y = NULL
f1()
```

## 6.5.4.4 Exercise {-}

:::question
I know this isn't exactly needed to answer the question, but how do we access a function that has methods? For instance - here I want to dig into the `hist` function using `hist`

```{r}
hist
```
does not give me the actual contents of the actual function....
:::

We need to access is using `hist.<method>`

```{r, eval=FALSE}
hist.default
```

## 6.6 dot dot dot {-}

:::question
"(See also `rlang::list2()` to support splicing and to silently ignore trailing commas..." Can we come up with a simple use case for `list2` here? The docs use `list2(a = 1, a = 2, b = 3, b = 4, 5, 6)` but how is this different from `list`?

```{r}
identical(
  rlang::list2(a = 1, a = 2, b = 3, b = 4, 5, 6) ,
  list(a = 1, a = 2, b = 3, b = 4, 5, 6)
)
```
:::

`list2` is most helpful when we need to force environment variables with ata variables. We can see this by crting a function that takes a variable number of arguments:

```{r}
library(rlang)

numeric_list <- function(...) {
  dots <- list(...)
  num <- as.numeric(dots)
  set_names(num, names(dots))
}

numeric_list2 <- function(...) {
  dots <- list2(...)
  num <- as.numeric(dots)
  set_names(num, names(dots))
}

numeric_list(1, 2, 3)
numeric_list2(1, 2, 3)
```

The main difference with list(...) is that list2(...) enables the `!!!` syntax to splice lists:

```{r}
x <- list(2, 3)
numeric_list2(1, !!! x, 4)
```

```{r, eval=FALSE}
numeric_list(1, !!! x, 4)
```

```
Error in !x : invalid argument type
```

:::question
"`lapply()` uses `...` to pass `na.rm` on to `mean()`" Um, how?

```{r}
x <- list(c(1, 3, NA), c(4, NA, 6))
str(lapply(x, mean, na.rm = TRUE))
```
:::

An lapply takes on two main arguments: what you want to loop over and the function to apply to each element. By including `...` `lapply` allows you to supply additional arguments which will be passed to the function inside the `lapply`. In this case, `na.rm = TRUE` is being applied to mean every time it's being called in the loop.

## 6.6.1.2 Exercise {-}

:::question
I tried running `browser(plot(1:10, col = "red"))` to peek under the hood but only got `Called from: top level` in the console. What am I missing?
:::

We can use `debugonce`!

```{r, eval=FALSE}
debugonce(plot())
```

## 6.7.4 Exit handlers {-}

:::question
"Always set `add = TRUE` when using `on.exit()` If you don’t, each call to `on.exit()` will overwrite the previous exit handler." What does this mean?
:::

`add = TRUE` is important when you have more than one `on.exit` function!

```{r}
j08 <- function() {
  on.exit(message("a"))
  on.exit(message("b"), add=TRUE)
}

j08()
```


:::question
Can we go over this code? How does it not change your working directory after you run the function

```{r}
cleanup <- function(dir, code) {
  old_dir <- setwd(dir)
  on.exit(setwd(old_dir), add = TRUE)
  
  old_opt <- options(stringsAsFactors = FALSE)
  on.exit(options(old_opt), add = TRUE)
}


cleanup("~")
getwd()
```
:::

The behavior of [`setwd`](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/getwd) "changing the working directory" is actually a **side effect** of the function - it invisibly returns the previous working directory as the value of the function (potentially for the exact purpose demonstrated). We can use this within our `on.exit` function to change back to the prior working directory! 


:::question
If `on.exit` fails will it continue onto the next `on.exit` so long as `add == TRUE`
?``on.exit fails it'll caontinue onto the next one
:::

```{r, eval=FALSE}
f <- function() {
  on.exit(stop("Error"))
  on.exit(message("yay, still called."), add = TRUE)
}
f()
```

```
Error in f() : Error
yay, still called.
```

## 6.7.5.4 Exercise {-}

:::question
[This question is flagged as "started" let's try to complete it!](https://github.com/Tazinho/Advanced-R-Solutions/blob/5043d9b06c7469a010c568ecb85e12bedca75207/2-06-Functions.Rmd#L350) Hadley comments in the repo: "I think I'm more interested in supplying a path vs. a logical value here".
:::

__[Q]{.Q}__: How does the `chdir` parameter of `source()` compare to `in_dir()`? Why might you prefer one approach to the other?
   The `in_dir()` approach was given in the book as
       
```{r, eval = FALSE}
    in_dir <- function(dir, code) {
      old <- setwd(dir)
      on.exit(setwd(old))
      
      force(code)
    }
```
    
   __[A]{.started}__: `in_dir()` takes a path to a working directory as an argument. First the working directory is changed accordingly. `on.exit()` ensures that the modification to the working directory are reset to the initial value when the function exits.
    
   In `source()` the `chdir` argument specifies if the working directory should be changed during the evaluation of the `file` argument (which in this case has to be a path name). 

:::TODO
XXX
:::

## 6.7.5.5 Exercise {-}

:::question
Can we go over the source code of `capture.output` and `capture.output2`? 

```{r}
body(capture.output)
```

```{r}
capture.output2 <- function(code) {
  temp <- tempfile()
  on.exit(file.remove(temp), add = TRUE)

  sink(temp)
  on.exit(sink(), add = TRUE)

  force(code)
  readLines(temp)
}
```

```{r}
identical(
  capture.output(cat("a", "b", "c", sep = "\n")),
  capture.output2(cat("a", "b", "c", sep = "\n"))
)
```

The second function is more concise but what is it missing from the first? I'd like to go over the first one line by line.
:::

:::TODO
```{r}
capture_output <- function(..., file = NULL, append, type = "output", split = FALSE) {
  # create a list from the arguments
  # but how does c("a", "b", "c") become the args?
  args <- substitute(list(...))[-1L]
  # get type based on table of canditate values
  # but this errors when I try to just run 
  # type = "output" ?
  type <- match.arg(type)
  # Error in match.arg(type) : 'arg' must be of length 1
  rval <- NULL
  closeit <- TRUE
  # we can save the output to a textConnection if no file is specified
  # but what is a textConnection?
  # otherwise the output is saved to a file (I think?)
  if (is.null(file)) 
    # what is a text connection?
    # I know this returns a character vector but what is this function
    file <- textConnection("rval", "w", local = TRUE)
  else if (is.character(file)) 
    # what is a character file? What's happening here?
    file <- file(file, if (append)  "a" else "w")
  # this is similar to the character file but what is the difference?
  # what does it mean to inherit "connection"
  else if (inherits(file, "connection")) {
    if (!isOpen(file))
      open(file, if (append)  "a" else "w")
    else closeit <- FALSE
  }
  # what is sink?
  # is this what happened when you create a bad file extension to save your output?
  else stop("'file' must be NULL, a character string or a connection")
  sink(file, type = type, split = split)
  # we're using on.exit here! 
  # ...but what is it doing exactly?
  on.exit({
    sink(type = type, split = split)
    if (closeit) close(file)
  })
  # this is some environment term
  # maybe we can talk about this next week?
  pf <- parent.frame()
  # print value AND if visible or not 
  evalVis <- function(expr) withVisible(eval(expr, pf))
  # THIS IS THE ACTUAL CAPTURE FUNCTION MEAT AND POTATOES!
  for (i in seq_along(args)) {
    # I assume this should be for each "a" "b" "c"
    # but I'm struggling to go one without it and being able to step through
    expr <- args[[i]]
    tmp <- switch(mode(expr), expression = lapply(expr, evalVis), 
                  call = , name = list(evalVis(expr)), stop("bad argument"))
    for (item in tmp) if (item$visible) 
      print(item$value)
  }
  on.exit()
  sink(type = type, split = split)
  if (closeit) 
    close(file)
  if (is.null(rval)) 
    invisible(NULL)
  else rval
}
```
:::

## 6.8.4 Replacement functions {-}

:::question
Can we put into words the translation for 

```{r}
x <- c(a = 1, b = 2, c = 3)
names(x)
names(x)[2] <- "two"
names(x)
```

Being equal to

```{r, eval=FALSE}
`*tmp*` <- x
x <- `names<-`(`*tmp*`, `[<-`(names(`*tmp*`), 2, "two"))
rm(`*tmp*`)
```
:::

We can dig into the [source code](https://github.com/wch/r-source/blob/2cdea4811caa2417e2cf32a0c7ad3be70325eec1/src/main/eval.c#L2787), but the jist is that in order to implement these complex assignments:

1. Copy `x` into a temporary variable `*temp*`
2. `[<-(names(*tmp*), 2, "two")` modifies the second element of the names of `*temp*`, 
3. `names<-`(`*tmp*` assigns step 2 to `*temp*` names
4. Clean up by removing the temp variable

## 6.8.6.3 Exercise {-}

:::question
[This question is flagged as "started" let's try to complete it!](https://github.com/Tazinho/Advanced-R-Solutions/blob/5043d9b06c7469a010c568ecb85e12bedca75207/2-06-Functions.Rmd#L433)
:::


__[Q]{.Q}__: Explain why the following code fails:
    ```{r, eval = FALSE}
    modify(get("x"), 1) <- 10
    #> Error: target of assignment expands to non-language object
    ```
    
   __[A]{.started}__: First, let's define `x` and recall the definition of `modify()` from the textbook:
    
    ```{r}
    x <- 1:3
    
    `modify<-` <- function(x, position, value) {
      x[position] <- value
      x
    }
    ```


:::TODO
XXX
:::

<!--chapter:end:06-functions.Rmd-->

--- 
title: "Advanced R Companion"
author: "R4DS Reading Group"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
github-repo: rstudio/bookdown-demo
description: "This is a companion to Advanced R and supplement to Advanced R Solutions."
---

<!--chapter:end:Index.Rmd-->

